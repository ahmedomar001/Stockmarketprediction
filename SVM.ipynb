{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc7a3f9",
   "metadata": {},
   "source": [
    "# SVM  \n",
    "\n",
    "This will start with using SKLearn, but might change to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b74506",
   "metadata": {},
   "source": [
    "For now, only one stock will be used, so for now my file that takes in data will find that one stock, and it will be one from the sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "02d76d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data points: 13356 \t Results as success: 2607\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-01-1970</td>\n",
       "      <td>6.129808</td>\n",
       "      <td>6.209936</td>\n",
       "      <td>289536</td>\n",
       "      <td>6.219952</td>\n",
       "      <td>6.139824</td>\n",
       "      <td>1.267613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-01-1970</td>\n",
       "      <td>6.059696</td>\n",
       "      <td>6.139824</td>\n",
       "      <td>529152</td>\n",
       "      <td>6.169872</td>\n",
       "      <td>6.109776</td>\n",
       "      <td>1.261409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-01-1970</td>\n",
       "      <td>5.899439</td>\n",
       "      <td>6.099760</td>\n",
       "      <td>443040</td>\n",
       "      <td>6.099760</td>\n",
       "      <td>5.929487</td>\n",
       "      <td>1.224188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-01-1970</td>\n",
       "      <td>5.949519</td>\n",
       "      <td>5.949519</td>\n",
       "      <td>575328</td>\n",
       "      <td>6.039663</td>\n",
       "      <td>5.959535</td>\n",
       "      <td>1.230390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-01-1970</td>\n",
       "      <td>5.979567</td>\n",
       "      <td>5.979567</td>\n",
       "      <td>1737216</td>\n",
       "      <td>6.069712</td>\n",
       "      <td>6.009615</td>\n",
       "      <td>1.240731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13351</th>\n",
       "      <td>06-12-2022</td>\n",
       "      <td>84.470001</td>\n",
       "      <td>86.610001</td>\n",
       "      <td>5883900</td>\n",
       "      <td>87.099998</td>\n",
       "      <td>85.279999</td>\n",
       "      <td>85.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13352</th>\n",
       "      <td>07-12-2022</td>\n",
       "      <td>84.820000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4860600</td>\n",
       "      <td>86.080002</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13353</th>\n",
       "      <td>08-12-2022</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>85.599998</td>\n",
       "      <td>6438400</td>\n",
       "      <td>86.190002</td>\n",
       "      <td>83.629997</td>\n",
       "      <td>83.629997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13354</th>\n",
       "      <td>09-12-2022</td>\n",
       "      <td>81.330002</td>\n",
       "      <td>83.620003</td>\n",
       "      <td>5539000</td>\n",
       "      <td>83.800003</td>\n",
       "      <td>81.449997</td>\n",
       "      <td>81.449997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>12-12-2022</td>\n",
       "      <td>81.029999</td>\n",
       "      <td>81.720001</td>\n",
       "      <td>1109941</td>\n",
       "      <td>81.940002</td>\n",
       "      <td>81.824997</td>\n",
       "      <td>81.824997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13356 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Low       Open   Volume       High      Close  \\\n",
       "0      02-01-1970   6.129808   6.209936   289536   6.219952   6.139824   \n",
       "1      05-01-1970   6.059696   6.139824   529152   6.169872   6.109776   \n",
       "2      06-01-1970   5.899439   6.099760   443040   6.099760   5.929487   \n",
       "3      07-01-1970   5.949519   5.949519   575328   6.039663   5.959535   \n",
       "4      08-01-1970   5.979567   5.979567  1737216   6.069712   6.009615   \n",
       "...           ...        ...        ...      ...        ...        ...   \n",
       "13351  06-12-2022  84.470001  86.610001  5883900  87.099998  85.279999   \n",
       "13352  07-12-2022  84.820000  85.000000  4860600  86.080002  85.000000   \n",
       "13353  08-12-2022  82.690002  85.599998  6438400  86.190002  83.629997   \n",
       "13354  09-12-2022  81.330002  83.620003  5539000  83.800003  81.449997   \n",
       "13355  12-12-2022  81.029999  81.720001  1109941  81.940002  81.824997   \n",
       "\n",
       "       Adjusted Close  \n",
       "0            1.267613  \n",
       "1            1.261409  \n",
       "2            1.224188  \n",
       "3            1.230390  \n",
       "4            1.240731  \n",
       "...               ...  \n",
       "13351       85.279999  \n",
       "13352       85.000000  \n",
       "13353       83.629997  \n",
       "13354       81.449997  \n",
       "13355       81.824997  \n",
       "\n",
       "[13356 rows x 7 columns]"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def stock_csv_parser(stock):\n",
    "\n",
    "    fileName = \"stock_market_data/sp500/csv/\" + stock + \".csv\"\n",
    "    df = pd.read_csv(fileName)\n",
    "\n",
    "    return df\n",
    "\n",
    "symbol_df = stock_csv_parser(\"GE\")\n",
    "\n",
    "# I want to get the percentage change, so if I wanted to make a threshold such as 2%\n",
    "# I will first drop any open if it is zero just in case to prevent division by zero\n",
    "symbol_df = symbol_df[symbol_df['Open'] != 0]\n",
    "y = symbol_df['Close'] / symbol_df['Open']\n",
    "\n",
    "y = [1 if each > 1.01 else 0 for each in y]\n",
    "\n",
    "# print(y)\n",
    "print(\"data points:\", str(len(y)), \"\\t Results as success:\", np.count_nonzero(y))\n",
    "symbol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ce79f",
   "metadata": {},
   "source": [
    "Now that we have one of the stock in, we will try to moddify the data, then train it with svm for now\n",
    "I will come back later to get it to do more than just one stock, this is for quicker testing for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "2a826382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Low       Open   Volume       High      Close  Adjusted Close\n",
      "0       6.129808   6.209936   289536   6.219952   6.139824        1.267613\n",
      "1       6.059696   6.139824   529152   6.169872   6.109776        1.261409\n",
      "2       5.899439   6.099760   443040   6.099760   5.929487        1.224188\n",
      "3       5.949519   5.949519   575328   6.039663   5.959535        1.230390\n",
      "4       5.979567   5.979567  1737216   6.069712   6.009615        1.240731\n",
      "...          ...        ...      ...        ...        ...             ...\n",
      "13351  84.470001  86.610001  5883900  87.099998  85.279999       85.279999\n",
      "13352  84.820000  85.000000  4860600  86.080002  85.000000       85.000000\n",
      "13353  82.690002  85.599998  6438400  86.190002  83.629997       83.629997\n",
      "13354  81.330002  83.620003  5539000  83.800003  81.449997       81.449997\n",
      "13355  81.029999  81.720001  1109941  81.940002  81.824997       81.824997\n",
      "\n",
      "[13356 rows x 6 columns]\n",
      "[[-0.98525854 -0.98501805 -0.75006802 -0.98525494 -0.98544583 -1.00434018]\n",
      " [-0.98592897 -0.98568083 -0.6961149  -0.98572322 -0.98572985 -1.00442667]\n",
      " [-0.98746141 -0.98605955 -0.7155043  -0.98637881 -0.987434   -1.00494554]\n",
      " ...\n",
      " [-0.25316106 -0.23454291  0.63444055 -0.23748112 -0.25298476  0.14380981]\n",
      " [-0.2661659  -0.25325983  0.4319272  -0.25982922 -0.27359079  0.11342012]\n",
      " [-0.26903464 -0.27122056 -0.56534158 -0.27722148 -0.27004618  0.11864771]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "try:\n",
    "    symbol_df = symbol_df.drop(['Date'], axis = 1)\n",
    "except:\n",
    "    print(\"Column missing\")\n",
    "\n",
    "print(symbol_df)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(symbol_df)\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd92141",
   "metadata": {},
   "source": [
    "I am unsure if I should do PCA first or append 10 days to each other then do it\n",
    "I suspect I will do PCA after since each day will be highly correlated to the previous day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "092cba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_day_appender(day_info, day_ct=10):\n",
    "    result = []\n",
    "    for i in range(len(day_info) - (day_ct)):\n",
    "        result.append(day_info[i:i+day_ct, :].flatten())\n",
    "    return result\n",
    "\n",
    "day_ct = 10\n",
    "X = X_day_appender(X, day_ct)\n",
    "\n",
    "y = y[day_ct:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74bee53",
   "metadata": {},
   "source": [
    "I want to now use PCA because this data will all naturally be correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "a98a1121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.1937395  -1.40416431  0.02633708  0.09015554  0.22120365 -0.06508217\n",
      " -0.07190814] 13346 13346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "X_PCA = pca.fit_transform(X)\n",
    "\n",
    "print(X_PCA[0], len(X_PCA), len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211932c7",
   "metadata": {},
   "source": [
    "Now that I have done PCA, I want to split my data so that future data is not trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "81024f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# This will split up my data, while keeping it in order\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_PCA, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# I am removing some that are close or are in the train set at least part of the way\n",
    "X_test = X_test[day_ct+5:]\n",
    "y_test = y_test[day_ct+5:]\n",
    "\n",
    "# I am then shuffleing the data, thought that might have only been NN that needed this step, I am unsure\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e28480a",
   "metadata": {},
   "source": [
    "Now that I have done quite a bit to the data, I will train it using SVM\n",
    "I want to see if the results can have a high percision\n",
    "I think percision is what I want the most because I do not want to have bad days be prediceted as good days\n",
    "\n",
    "I will first be trying svc, because I want a classification\n",
    "I might move to one class svm because there is a great deal of the results not meeting the threshold\n",
    "\n",
    "I am using svc and not linear svc, because the documentation suggested linear svc if you have more than 10s of thousands of samples\n",
    "Which when only doing one stock with this data set, there is not too many samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "86ce8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1143c",
   "metadata": {},
   "source": [
    "Now that it is train, I want to see what I can get out of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "3c419cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8090395480225989 \tPrecision:  0.6428571428571429 \tRecall:  0.01761252446183953 \tNumber of predicted days:  14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", str(accuracy),  \"\\tPrecision: \", str(precision), \"\\tRecall: \", str(recall), \"\\tNumber of predicted days: \", str(np.count_nonzero(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178de0f",
   "metadata": {},
   "source": [
    "So far the results are not great, I will continute to work to see if I can get any sort of result from this\n",
    "I have tried a few stocks and General Electric is returning the best results so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bd11d",
   "metadata": {},
   "source": [
    "I plan to also add in a way to see the change in value if when predicted to be a good day, the stock is bought at open and sold at close\n",
    "I plan to also try to test all sp500 stocks at once to see which ones give the best results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
